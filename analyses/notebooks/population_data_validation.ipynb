{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd40f4f4-5a80-40b7-94b3-aed136daa9d8",
   "metadata": {},
   "source": [
    "# Validation Analysis of the SSP3 and SPP5 Population Data\n",
    "\n",
    "This notebook tests the population data that goes into GCAM-USA and TELL to confirm that they add to the same nationwide and state-level total populations for SSP3 and SSP5. The raw state-level data is taken directly from the Jiang et al. population dataset (https://zenodo.org/records/3956412) and aggregate using the functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e597e9-538f-41d4-afa9-a268b10ab1df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start by importing the packages we need:\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f6fe5-0769-4298-887e-7c4cffc64a0d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd887600-32da-46dc-b411-fa63c75f564f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify the top-level directory and the subdirectory where the data will be stored:\n",
    "data_input_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/population_data/'\n",
    "image_output_dir =  '/Users/burl878/Documents/code_repos/exp_group_b_test/analyses/plots/population_validation/'\n",
    "\n",
    "# If the \"image_output_dir\" subdirectory doesn't exist then create it:\n",
    "if not os.path.exists(image_output_dir):\n",
    "   os.makedirs(image_output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f055d71-411a-4b85-b0b8-5fd3f9059796",
   "metadata": {},
   "source": [
    "## Process the Raw SSP3 and SSP5 Population Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04f656-5fab-4fcb-86db-63c64db9c2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function aggregate the raw population data for a given scenario:\n",
    "def process_state_level_population_data(data_input_dir: str, scenario_to_process: str):\n",
    "    \n",
    "    # Make a list of all the state subdirectories in the folder:\n",
    "    dir_list = glob(os.path.join((data_input_dir + 'Jiang_et_al_Population/' + scenario_to_process + '/'), \"*\", \"\"), recursive = True)\n",
    "    \n",
    "    # Loop over the directories and process the data for each state:\n",
    "    for i in range(len(dir_list)):\n",
    "        \n",
    "        # Strip out the name of the directory being processed:\n",
    "        dir_name = dir_list[i].split(scenario_to_process)[1].replace('/', '')\n",
    "                \n",
    "        # Extract the state FIPS code and state abbreviation from the directory name:\n",
    "        state_fips = int(dir_name.split('-')[0])*1000\n",
    "        state_abbreviation = dir_name.split('-')[1]\n",
    "              \n",
    "        # Read in the '*_proj_pop.csv' file for that state:\n",
    "        pop_df = pd.read_csv((data_input_dir + 'Jiang_et_al_Population/' + scenario_to_process + '/' + dir_name + '/' + dir_name + '_proj_pop.csv'))\n",
    "\n",
    "        # Remove the first four columns:\n",
    "        pop_df.drop(['state', 'age', 'female', 'urban'], axis=1, inplace=True)\n",
    "        \n",
    "        # Sum over all the rows to get the total population by year:\n",
    "        sum_pop_df = pd.DataFrame(pop_df.sum(axis=0).round(2), columns =['Nat_Res_Pop']).reset_index()\n",
    "        sum_pop_df.rename(columns={'index': 'Year'}, inplace=True)\n",
    "\n",
    "        # Add in the scenario, state abbreviation, and FIPS codes:\n",
    "        sum_pop_df['Scenario'] = scenario_to_process\n",
    "        sum_pop_df['State_FIPS'] = state_fips\n",
    "        sum_pop_df['State'] = state_abbreviation\n",
    "    \n",
    "        # Aggregate the output into a new dataframe:\n",
    "        if i == 0:\n",
    "           output_df = sum_pop_df\n",
    "        else:\n",
    "           output_df = pd.concat([output_df, sum_pop_df])\n",
    "        \n",
    "        # Clean up:\n",
    "        del dir_name, state_fips, state_abbreviation, pop_df, sum_pop_df\n",
    "\n",
    "    # Reorder the columns and sort by state name:\n",
    "    output_df = output_df[['State', 'State_FIPS', 'Scenario', 'Year', 'Nat_Res_Pop']].copy().sort_values(['State', 'Year']).reset_index(drop=True)      \n",
    "    \n",
    "    # Subset to just the future years that match the county-level data:\n",
    "    output_df = output_df[output_df['Year'].isin(['2020', '2030', '2040', '2050', '2060', '2070', '2080', '2090', '2100'])]\n",
    "    \n",
    "    # Return the final dataframe:\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2acf68-a46f-45e6-b16a-a664da973889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute the function created above:\n",
    "output_df = process_state_level_population_data(data_input_dir = data_input_dir, \n",
    "                                                scenario_to_process = 'SSP3')\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c47353-0c91-42e5-839f-d19f1e3d0133",
   "metadata": {},
   "source": [
    "## Process the County-Level Data to the Same Resolution and Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7af3e4-da3f-4a67-a2a9-8a9a99ae419e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function aggregate the raw county-level population data for a given scenario:\n",
    "def process_county_level_population_data(data_input_dir: str, scenario_to_process: str):\n",
    "    \n",
    "    # Read in the raw county-level population data for that scenario:\n",
    "    if scenario_to_process == 'SSP3':\n",
    "       pop_df = pd.read_csv((data_input_dir + 'ssp3_county_population.csv'))\n",
    "    elif scenario_to_process == 'SSP5':\n",
    "       pop_df = pd.read_csv((data_input_dir + 'ssp5_county_population.csv'))\n",
    "    \n",
    "    # Convert the county FIPS code to a state FIPS code:\n",
    "    pop_df['State_FIPS'] = (((pop_df['FIPS']/1000).apply(np.floor))*1000).astype(int)\n",
    "    \n",
    "    # Write out the dataframe to a .csv file:\n",
    "    pop_df.to_csv((data_input_dir + 'Test.csv'), sep=',', index=False)\n",
    "    \n",
    "    # Drop the county FIPS and state_name columns:\n",
    "    pop_df.drop(['FIPS', 'state_name'], axis=1, inplace=True)\n",
    "    \n",
    "    # Return the final dataframe:\n",
    "    return pop_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80297a1e-b1b7-408e-9aa3-8eab4cb85e48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute the function created above:\n",
    "output_df = process_county_level_population_data(data_input_dir = data_input_dir, \n",
    "                                                 scenario_to_process = 'SSP3')\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14ed3a-1ba1-4408-a268-ab29fba14cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
