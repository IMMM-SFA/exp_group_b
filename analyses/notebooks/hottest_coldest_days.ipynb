{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd40f4f4-5a80-40b7-94b3-aed136daa9d8",
   "metadata": {},
   "source": [
    "# Process the Date and Time of the Annual Hottest and Coldest Hour by Balancing Authority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e597e9-538f-41d4-afa9-a268b10ab1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the packages we need:\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f6fe5-0769-4298-887e-7c4cffc64a0d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd887600-32da-46dc-b411-fa63c75f564f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the data input and output directories:\n",
    "data_input_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/wrf_to_tell_data/historic/'\n",
    "metadata_input_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Analysis/'\n",
    "data_output_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Analysis/Hottest_Coldest_Days/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afedcfd4-7a50-42aa-8479-8474ecbb85cf",
   "metadata": {},
   "source": [
    "## Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89bd4390-d050-4775-812a-d16be35efa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b04f656-5fab-4fcb-86db-63c64db9c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process the daily maximum and minimum temperature time series:\n",
    "def process_hottest_coldest_days_time_series(data_input_dir: str, metadata_input_dir: str, data_output_dir: str, interconnection_to_process: str):\n",
    "    \n",
    "    # Read in the BA-to-Interconnection mapping file:\n",
    "    ba_mapping = pd.read_csv(metadata_input_dir + 'BA_to_Interconnection_Mapping.csv')\n",
    "    \n",
    "    # Subset to just the BAs for the interconnection being processed:\n",
    "    ba_mapping = ba_mapping.loc[ba_mapping['Interconnection'] == interconnection_to_process]\n",
    "    \n",
    "    # Make a list of all of the BAs in \"ba_mapping\":\n",
    "    bas = ba_mapping['BA_Code'].unique()\n",
    "    \n",
    "    #Initiate a counter to store the results:\n",
    "    counter = 0;\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    # Loop over the BAs and find the hottest and coldest day for each year:\n",
    "    for i in range(len(bas)):\n",
    "        # Loop over the years from the 1980 to 2019:\n",
    "        for year in range(1980,2020,1):\n",
    "            # Iterate the counter by one:\n",
    "            counter = counter + 1\n",
    "            \n",
    "            # Create the filename for the given BA and year combination:\n",
    "            filename = (data_input_dir + bas[i] + '_WRF_Hourly_Mean_Meteorology_' + str(year) + '.csv')\n",
    "    \n",
    "            # Read in the .csv file:\n",
    "            met_df = pd.read_csv(filename)\n",
    "    \n",
    "            # Set the time variable as an index:\n",
    "            met_df.index = pd.to_datetime(met_df['Time_UTC'])\n",
    "        \n",
    "            # Convert the temperature from Kelvin to Fahrenheit:\n",
    "            met_df['T2'] = (1.8 * (met_df['T2'] - 273)) + 32\n",
    "    \n",
    "            # Add the hottest and coldest times to the output file:\n",
    "            output_df.loc[counter, 'BA'] = bas[i]\n",
    "            output_df.loc[counter, 'Year'] = str(year)\n",
    "            output_df.loc[counter, 'Coldest_Hour_UTC'] = met_df['Time_UTC'].loc[met_df['T2'].idxmin()]\n",
    "            output_df.loc[counter, 'Coldest_Temp_F'] = met_df['T2'].min().round(2)\n",
    "            output_df.loc[counter, 'Hottest_Hour_UTC'] = met_df['Time_UTC'].loc[met_df['T2'].idxmax()]\n",
    "            output_df.loc[counter, 'Hottest_Temp_F'] = met_df['T2'].max().round(2)\n",
    "        \n",
    "            # Clean up and move to the next year:\n",
    "            del filename, met_df\n",
    "        \n",
    "    # Write out the dataframe to a .csv file:\n",
    "    output_df.to_csv((os.path.join(data_output_dir + interconnection_to_process + '_Hottest_Coldest_Days_1980_to_2019.csv')), sep=',', index=False)\n",
    "    \n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b38e6c6d-8983-4b44-8901-68b335b9c30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BA</th>\n",
       "      <th>Year</th>\n",
       "      <th>Coldest_Hour_UTC</th>\n",
       "      <th>Coldest_Temp_F</th>\n",
       "      <th>Hottest_Hour_UTC</th>\n",
       "      <th>Hottest_Temp_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVA</td>\n",
       "      <td>1980</td>\n",
       "      <td>1980-01-29 15:00:00</td>\n",
       "      <td>-10.19</td>\n",
       "      <td>1980-07-22 23:00:00</td>\n",
       "      <td>96.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVA</td>\n",
       "      <td>1981</td>\n",
       "      <td>1981-02-10 15:00:00</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>1981-08-13 23:00:00</td>\n",
       "      <td>95.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVA</td>\n",
       "      <td>1982</td>\n",
       "      <td>1982-01-06 15:00:00</td>\n",
       "      <td>-15.54</td>\n",
       "      <td>1982-08-07 23:00:00</td>\n",
       "      <td>93.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVA</td>\n",
       "      <td>1983</td>\n",
       "      <td>1983-12-23 16:00:00</td>\n",
       "      <td>-15.07</td>\n",
       "      <td>1983-08-07 23:00:00</td>\n",
       "      <td>95.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AVA</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984-12-19 06:00:00</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>1984-07-25 23:00:00</td>\n",
       "      <td>96.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>WAUW</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-01-09 07:00:00</td>\n",
       "      <td>-8.05</td>\n",
       "      <td>2015-08-14 20:00:00</td>\n",
       "      <td>96.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>WAUW</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-12-17 13:00:00</td>\n",
       "      <td>-19.32</td>\n",
       "      <td>2016-07-22 21:00:00</td>\n",
       "      <td>95.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>WAUW</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-12-31 10:00:00</td>\n",
       "      <td>-16.42</td>\n",
       "      <td>2017-07-08 22:00:00</td>\n",
       "      <td>95.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>WAUW</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-02-20 14:00:00</td>\n",
       "      <td>-16.15</td>\n",
       "      <td>2018-08-11 21:00:00</td>\n",
       "      <td>99.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>WAUW</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-03-03 14:00:00</td>\n",
       "      <td>-24.63</td>\n",
       "      <td>2019-08-02 22:00:00</td>\n",
       "      <td>91.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1120 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BA  Year     Coldest_Hour_UTC  Coldest_Temp_F     Hottest_Hour_UTC  \\\n",
       "1      AVA  1980  1980-01-29 15:00:00          -10.19  1980-07-22 23:00:00   \n",
       "2      AVA  1981  1981-02-10 15:00:00           -1.98  1981-08-13 23:00:00   \n",
       "3      AVA  1982  1982-01-06 15:00:00          -15.54  1982-08-07 23:00:00   \n",
       "4      AVA  1983  1983-12-23 16:00:00          -15.07  1983-08-07 23:00:00   \n",
       "5      AVA  1984  1984-12-19 06:00:00           -3.28  1984-07-25 23:00:00   \n",
       "...    ...   ...                  ...             ...                  ...   \n",
       "1116  WAUW  2015  2015-01-09 07:00:00           -8.05  2015-08-14 20:00:00   \n",
       "1117  WAUW  2016  2016-12-17 13:00:00          -19.32  2016-07-22 21:00:00   \n",
       "1118  WAUW  2017  2017-12-31 10:00:00          -16.42  2017-07-08 22:00:00   \n",
       "1119  WAUW  2018  2018-02-20 14:00:00          -16.15  2018-08-11 21:00:00   \n",
       "1120  WAUW  2019  2019-03-03 14:00:00          -24.63  2019-08-02 22:00:00   \n",
       "\n",
       "      Hottest_Temp_F  \n",
       "1              96.76  \n",
       "2              95.52  \n",
       "3              93.36  \n",
       "4              95.38  \n",
       "5              96.15  \n",
       "...              ...  \n",
       "1116           96.21  \n",
       "1117           95.22  \n",
       "1118           95.18  \n",
       "1119           99.19  \n",
       "1120           91.65  \n",
       "\n",
       "[1120 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = process_hottest_coldest_days_time_series(data_input_dir = data_input_dir, \n",
    "                                                     metadata_input_dir = metadata_input_dir,\n",
    "                                                     data_output_dir = data_output_dir, \n",
    "                                                     interconnection_to_process = 'WECC')\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1065640-9587-4f26-ad97-b7cfc846c329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
