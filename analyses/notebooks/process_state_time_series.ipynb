{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd40f4f4-5a80-40b7-94b3-aed136daa9d8",
   "metadata": {},
   "source": [
    "# Process State-Level Population-Weighted Meteorology Time Series\n",
    "\n",
    "This notebook process the time-series of historical population-weighted meteorology for each of the 48 contiguous U.S. states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e597e9-538f-41d4-afa9-a268b10ab1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the packages we need:\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f6fe5-0769-4298-887e-7c4cffc64a0d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd887600-32da-46dc-b411-fa63c75f564f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the data input and output directories:\n",
    "data_input_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Temporary/'\n",
    "metadata_input_dir = '/Users/burl878/Documents/IMMM/Data/TELL_Input_Data/forward_execution/Population_Forcing/'\n",
    "data_output_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/State_Meteorology_Time_Series/historic/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f055d71-411a-4b85-b0b8-5fd3f9059796",
   "metadata": {},
   "source": [
    "## Process the Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b41c7-c488-4716-99d1-c98f4a91b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the county-level population data:\n",
    "pop_df = pd.read_csv(metadata_input_dir + 'county_populations_2000_to_2019_long_format.csv')\n",
    "\n",
    "# Subset the dataframe to only the year 2019:\n",
    "pop_df = pop_df[pop_df['Year'] == 2019].copy()\n",
    "\n",
    "# Rename the FIPS variable for consistency with the meteorology data:\n",
    "pop_df.rename(columns={'County_FIPS': 'FIPS'}, inplace=True)\n",
    "\n",
    "# Read in the county-to-state mapping file:\n",
    "state_df = pd.read_csv(metadata_input_dir + 'state_and_county_fips_codes.csv')\n",
    "\n",
    "# Rename the FIPS variable for consistency with the meteorology data and shorten the state name variable:\n",
    "state_df.rename(columns={'county_FIPS': 'FIPS', 'state_name': 'State'}, inplace=True)\n",
    "\n",
    "# Merge the two dataframes together based on common FIPS values:\n",
    "pop_df = pop_df.merge(state_df, on=['FIPS'])\n",
    "\n",
    "# Compute the fraction of the total population in each state that lives in a given county:\n",
    "pop_df['Population_Sum'] = pop_df.groupby('State')['Population'].transform('sum')\n",
    "pop_df['Population_Fraction'] = pop_df['Population'] / pop_df['Population_Sum']\n",
    "\n",
    "# Subset the dataframe and sort by FIPS code:\n",
    "pop_df = pop_df[['FIPS', 'State', 'Population', 'Population_Fraction']]\n",
    "pop_df = pop_df.sort_values(['FIPS'])\n",
    "\n",
    "# Return the dataframe:\n",
    "pop_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04f656-5fab-4fcb-86db-63c64db9c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process the state-level time series for a given year\n",
    "def process_state_meteorology_time_series(data_input_dir: str, data_output_dir: str, year: int):\n",
    "    \n",
    "    # Create a list of all county meteorology files in the input directory:\n",
    "    list_of_files = glob(os.path.join(data_input_dir, str(year), '*.csv'))\n",
    "    \n",
    "    # Loop over that list process each file:\n",
    "    for file in range(len(list_of_files)):\n",
    "        # Extract the filename from the list:\n",
    "        filename = list_of_files[file].rsplit('/', 1)[1]\n",
    "       \n",
    "        # Extract the time string from the name of the file:\n",
    "        filetime = filename.replace(\"_UTC_County_Mean_Meteorology.csv\", \"\")\n",
    "                \n",
    "        # Read in the .csv file:\n",
    "        met_df = pd.read_csv(list_of_files[file])\n",
    "        \n",
    "        # Compute the 10-m wind speed based on the U10 and V10 variables:\n",
    "        met_df['WSPD'] = (np.sqrt(np.square(met_df['U10']) + np.square(met_df['V10']))).round(2)\n",
    "        \n",
    "        # Merge the population data into the meteorology dataframe based on common FIPS values:\n",
    "        met_df = met_df.merge(pop_df, on=['FIPS'])\n",
    "        \n",
    "        # Population-weight the meteorological variables:\n",
    "        met_df['T2_Weighted'] = (met_df['T2'].mul(met_df['Population_Fraction']))\n",
    "        met_df['Q2_Weighted'] = (met_df['Q2'].mul(met_df['Population_Fraction']))\n",
    "        met_df['SWDOWN_Weighted'] = (met_df['SWDOWN'].mul(met_df['Population_Fraction']))\n",
    "        met_df['GLW_Weighted'] = (met_df['GLW'].mul(met_df['Population_Fraction']))\n",
    "        met_df['WSPD_Weighted'] = (met_df['WSPD'].mul(met_df['Population_Fraction']))\n",
    "        \n",
    "        # Sum up the population-weighted meteorological variables by state:\n",
    "        met_df['T2_Sum'] = (met_df.groupby('State')['T2_Weighted'].transform('sum')).round(2)\n",
    "        met_df['Q2_Sum'] = (met_df.groupby('State')['Q2_Weighted'].transform('sum')).round(5)\n",
    "        met_df['SWDOWN_Sum'] = (met_df.groupby('State')['SWDOWN_Weighted'].transform('sum')).round(2)\n",
    "        met_df['GLW_Sum'] = (met_df.groupby('State')['GLW_Weighted'].transform('sum')).round(2)\n",
    "        met_df['WSPD_Sum'] = (met_df.groupby('State')['WSPD_Weighted'].transform('sum')).round(2)\n",
    "        \n",
    "        # Copy the output to a new dataframe and remove the non-unique rows:\n",
    "        temp_df = met_df[['State', 'T2_Sum', 'Q2_Sum', 'SWDOWN_Sum', 'GLW_Sum', 'WSPD_Sum']].copy().drop_duplicates() \n",
    "        \n",
    "        # Add in the time variable:\n",
    "        temp_df['Time_UTC'] = pd.to_datetime(filetime, exact=False, format='%Y_%m_%d_%H')\n",
    "        \n",
    "        # Rename the variables for consistency and reorder them:\n",
    "        temp_df.rename(columns={'T2_Sum': 'T2', 'Q2_Sum': 'Q2', 'SWDOWN_Sum': 'SWDOWN', 'GLW_Sum': 'GLW', 'WSPD_Sum': 'WSPD'}, inplace=True)\n",
    "        temp_df = temp_df[['Time_UTC', 'State', 'T2', 'Q2', 'SWDOWN', 'GLW', 'WSPD']].copy()\n",
    "        \n",
    "        # Aggregate the output into a new dataframe:\n",
    "        if file == 0:\n",
    "            output_df = temp_df\n",
    "        else:\n",
    "            output_df = pd.concat([output_df, temp_df])\n",
    "            \n",
    "        # Clean up the old dataframes and move to the next file in the loop:\n",
    "        del filename, filetime, met_df, temp_df\n",
    "        \n",
    "    # Sort by state and then time:\n",
    "    output_df = output_df.sort_values(['State', 'Time_UTC'])\n",
    "\n",
    "    # Create the ouput filename:    \n",
    "    csv_output_filename = os.path.join(data_output_dir, ('State_Meteorology_' + str(year) + '.csv'))\n",
    "        \n",
    "    # Write out the dataframe to a .csv file:\n",
    "    output_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "    \n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e6c6d-8983-4b44-8901-68b335b9c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(1980,2020,1):\n",
    "    output_df = process_state_meteorology_time_series(data_input_dir = data_input_dir, \n",
    "                                                      data_output_dir = data_output_dir, \n",
    "                                                      year = year)\n",
    "\n",
    "output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d3f1c-726f-4210-8bbb-f5dccfb27c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
