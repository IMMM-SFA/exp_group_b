{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b5bb970-3870-437e-a954-ea097ba463cf",
   "metadata": {},
   "source": [
    "# Process Interconnection Population-Weighted Meteorology Time Series\n",
    "\n",
    "This notebook process the time-series of historical population-weighted meteorology for each of the three electricity interconnections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e597e9-538f-41d4-afa9-a268b10ab1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the packages we need:\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f6fe5-0769-4298-887e-7c4cffc64a0d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd887600-32da-46dc-b411-fa63c75f564f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the data input and output directories:\n",
    "data_input_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/wrf_tell_counties_output/'\n",
    "metadata_input_dir = '/Users/burl878/Documents/IMMM/Data/TELL_Input_Data/forward_execution/Population_Forcing/'\n",
    "data_output_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Analysis/Interconnection_Meteorology_Time_Series/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ee0b0-3a7e-41bb-99b5-84f0d402b230",
   "metadata": {},
   "source": [
    "## Set the Interconnections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27647568-c445-40ce-9701-846667558e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the states that are in each interconnection:\n",
    "wecc = ['Washington', 'Oregon', 'California', 'Nevada', 'Idaho', 'Montana', 'Arizona', 'Utah', 'New Mexico', 'Colorado', 'Wyoming']\n",
    "ercot = ['Texas']\n",
    "eic = ['Washington', 'Oregon', 'California', 'Nevada', 'Idaho', 'Montana', 'Arizona', 'Utah', 'New Mexico', 'Colorado', 'Wyoming', 'Texas']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f055d71-411a-4b85-b0b8-5fd3f9059796",
   "metadata": {},
   "source": [
    "## Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b41c7-c488-4716-99d1-c98f4a91b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the county-level population data:\n",
    "pop_df = pd.read_csv(metadata_input_dir + 'county_populations_2000_to_2019_long_format.csv')\n",
    "\n",
    "# Subset the dataframe to only the year 2019:\n",
    "pop_df = pop_df[pop_df['Year'] == 2019].copy()\n",
    "\n",
    "# Rename the FIPS variable for consistency with the meteorology data:\n",
    "pop_df.rename(columns={'County_FIPS': 'FIPS'}, inplace=True)\n",
    "\n",
    "# Read in the county-to-state mapping file:\n",
    "state_df = pd.read_csv(metadata_input_dir + 'state_and_county_fips_codes.csv')\n",
    "\n",
    "# Rename the FIPS variable for consistency with the meteorology data and shorten the state name variable:\n",
    "state_df.rename(columns={'county_FIPS': 'FIPS', 'state_name': 'State'}, inplace=True)\n",
    "\n",
    "# Merge the two dataframes together based on common FIPS values:\n",
    "pop_df = pop_df.merge(state_df, on=['FIPS'])\n",
    "\n",
    "# Subset the dataframe and sort by FIPS code:\n",
    "pop_df = pop_df[['FIPS', 'State', 'Population']]\n",
    "pop_df = pop_df.sort_values(['FIPS'])\n",
    "\n",
    "# Create an empty column:\n",
    "pop_df['Interconnection'] = np.nan\n",
    "        \n",
    "# Assign the interconnection:\n",
    "pop_df['Interconnection'].loc[pop_df['State'].isin(wecc)] = 'WECC'\n",
    "pop_df['Interconnection'].loc[pop_df['State'].isin(ercot)] = 'ERCOT'\n",
    "pop_df['Interconnection'].loc[~pop_df['State'].isin(eic)] = 'EIC'\n",
    "\n",
    "# Return the dataframe:\n",
    "pop_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04f656-5fab-4fcb-86db-63c64db9c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process the interconnection-level time series for a given year\n",
    "def process_ics_meteorology_time_series(data_input_dir: str, data_output_dir: str, scenario: str, year: int):\n",
    "    \n",
    "    # Create a list of all county meteorology files in the input directory:\n",
    "    list_of_files = glob(os.path.join(data_input_dir, scenario, str(year), '*.csv'))\n",
    "    \n",
    "    # Loop over that list process each file:\n",
    "    for file in range(len(list_of_files)):\n",
    "    \n",
    "        # Extract the filename from the list:\n",
    "        filename = list_of_files[file].rsplit('/', 1)[1]\n",
    "       \n",
    "        # Extract the time string from the name of the file:\n",
    "        filetime = filename.replace(\"_UTC_County_Mean_Meteorology.csv\", \"\")\n",
    "                \n",
    "        # Read in the .csv file:\n",
    "        met_df = pd.read_csv(list_of_files[file])\n",
    "        \n",
    "        # Compute the 10-m wind speed based on the U10 and V10 variables:\n",
    "        met_df['WSPD'] = (np.sqrt(np.square(met_df['U10']) + np.square(met_df['V10']))).round(2)\n",
    "        \n",
    "        # Merge the population data into the meteorology dataframe based on common FIPS values:\n",
    "        met_df = met_df.merge(pop_df, on=['FIPS'])\n",
    "               \n",
    "        # Compute the fraction of the total population in each state that lives in a given county:\n",
    "        met_df['Population_Sum'] = met_df.groupby('Interconnection')['Population'].transform('sum')\n",
    "        met_df['Population_Fraction'] = met_df['Population'] / met_df['Population_Sum']\n",
    "\n",
    "        # Population-weight the meteorological variables:\n",
    "        met_df['T2_Weighted'] = (met_df['T2'].mul(met_df['Population_Fraction']))\n",
    "        met_df['Q2_Weighted'] = (met_df['Q2'].mul(met_df['Population_Fraction']))\n",
    "        met_df['SWDOWN_Weighted'] = (met_df['SWDOWN'].mul(met_df['Population_Fraction']))\n",
    "        met_df['GLW_Weighted'] = (met_df['GLW'].mul(met_df['Population_Fraction']))\n",
    "        met_df['WSPD_Weighted'] = (met_df['WSPD'].mul(met_df['Population_Fraction']))\n",
    "        \n",
    "        # Sum up the population-weighted meteorological variables by state:\n",
    "        met_df['T2_Sum'] = (met_df.groupby('Interconnection')['T2_Weighted'].transform('sum')).round(2)\n",
    "        met_df['Q2_Sum'] = (met_df.groupby('Interconnection')['Q2_Weighted'].transform('sum')).round(5)\n",
    "        met_df['SWDOWN_Sum'] = (met_df.groupby('Interconnection')['SWDOWN_Weighted'].transform('sum')).round(2)\n",
    "        met_df['GLW_Sum'] = (met_df.groupby('Interconnection')['GLW_Weighted'].transform('sum')).round(2)\n",
    "        met_df['WSPD_Sum'] = (met_df.groupby('Interconnection')['WSPD_Weighted'].transform('sum')).round(2)\n",
    "        \n",
    "        # Copy the output to a new dataframe and remove the non-unique rows:\n",
    "        temp_df = met_df[['Interconnection', 'T2_Sum', 'Q2_Sum', 'SWDOWN_Sum', 'GLW_Sum', 'WSPD_Sum']].copy().drop_duplicates() \n",
    "        \n",
    "        # Add in the time variable:\n",
    "        temp_df['Time_UTC'] = pd.to_datetime(filetime, exact=False, format='%Y_%m_%d_%H')\n",
    "        \n",
    "        # Rename the variables for consistency and reorder them:\n",
    "        temp_df.rename(columns={'T2_Sum': 'T2', 'Q2_Sum': 'Q2', 'SWDOWN_Sum': 'SWDOWN', 'GLW_Sum': 'GLW', 'WSPD_Sum': 'WSPD'}, inplace=True)\n",
    "        temp_df = temp_df[['Time_UTC', 'Interconnection', 'T2', 'Q2', 'SWDOWN', 'GLW', 'WSPD']].copy()\n",
    "        \n",
    "        # Aggregate the output into a new dataframe:\n",
    "        if file == 0:\n",
    "           output_df = temp_df\n",
    "        else:\n",
    "           output_df = pd.concat([output_df, temp_df])\n",
    "            \n",
    "        # Clean up the old dataframes and move to the next file in the loop:\n",
    "        del filename, filetime, met_df, temp_df\n",
    "        \n",
    "    # Sort by state and then time:\n",
    "    output_df = output_df.sort_values(['Interconnection', 'Time_UTC'])\n",
    "\n",
    "    # Create the ouput filename:    \n",
    "    csv_output_filename = os.path.join(data_output_dir, scenario, ('Interconnection_Meteorology_' + str(year) + '.csv'))\n",
    "        \n",
    "    # Write out the dataframe to a .csv file:\n",
    "    output_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "    \n",
    "    # Print out the progress:\n",
    "    print(('Scenario = ' + scenario + ', Year = ' + str(year)))\n",
    "    \n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e6c6d-8983-4b44-8901-68b335b9c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year_to_process in range(2060,2100,1):\n",
    "    output_df = process_ics_meteorology_time_series(data_input_dir = data_input_dir, \n",
    "                                                    data_output_dir = data_output_dir,\n",
    "                                                    scenario = 'rcp85cooler',\n",
    "                                                    year = year_to_process)\n",
    "\n",
    "for year_to_process in range(2060,2100,1):\n",
    "    output_df = process_ics_meteorology_time_series(data_input_dir = data_input_dir, \n",
    "                                                    data_output_dir = data_output_dir,\n",
    "                                                    scenario = 'rcp85hotter',\n",
    "                                                    year = year_to_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30dc458-9c31-4716-b606-8717249653c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
