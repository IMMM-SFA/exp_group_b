{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b5bb970-3870-437e-a954-ea097ba463cf",
   "metadata": {},
   "source": [
    "# Process Interconnection Population-Weighted Meteorology Time Series\n",
    "\n",
    "This notebook process the time-series of historical population-weighted meteorology for each of the three electricity interconnections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27e597e9-538f-41d4-afa9-a268b10ab1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the packages we need:\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f6fe5-0769-4298-887e-7c4cffc64a0d",
   "metadata": {},
   "source": [
    "## Set the Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd887600-32da-46dc-b411-fa63c75f564f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Identify the data input and output directories:\n",
    "data_input_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Production_Runs/tell_data/wrf_tell_counties_output/historic/'\n",
    "metadata_input_dir = '/Users/burl878/Documents/IMMM/Data/TELL_Input_Data/forward_execution/Population_Forcing/'\n",
    "data_output_dir =  '/Users/burl878/Documents/IMMM/Data/TELL/Analysis/Interconnection_Meteorology_Time_Series/'\n",
    "image_output_dir =  '/Users/burl878/Documents/IMMM/Images/TELL/Analysis/Interconnection_Meteorology_Time_Series/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ee0b0-3a7e-41bb-99b5-84f0d402b230",
   "metadata": {},
   "source": [
    "## Set the Interconnections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27647568-c445-40ce-9701-846667558e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the states that are in each interconnection:\n",
    "wecc = ['Washington', 'Oregon', 'California', 'Nevada', 'Idaho', 'Montana', 'Arizona', 'Utah', 'New Mexico', 'Colorado', 'Wyoming']\n",
    "ercot = ['Texas']\n",
    "eic = ['Washington', 'Oregon', 'California', 'Nevada', 'Idaho', 'Montana', 'Arizona', 'Utah', 'New Mexico', 'Colorado', 'Wyoming', 'Texas']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f055d71-411a-4b85-b0b8-5fd3f9059796",
   "metadata": {},
   "source": [
    "## Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947b41c7-c488-4716-99d1-c98f4a91b5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tw/332pg48n0cb0jrl9_s87l48m0000gn/T/ipykernel_6339/4254740590.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pop_df['Interconnection'].loc[pop_df['State'].isin(wecc)] = 'WECC'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Interconnection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>55869</td>\n",
       "      <td>EIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>223234</td>\n",
       "      <td>EIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1005</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>24686</td>\n",
       "      <td>EIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1007</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>22394</td>\n",
       "      <td>EIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>57826</td>\n",
       "      <td>EIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>56037</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>42343</td>\n",
       "      <td>WECC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>56039</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>23464</td>\n",
       "      <td>WECC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>56041</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>20226</td>\n",
       "      <td>WECC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>56043</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>7805</td>\n",
       "      <td>WECC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>56045</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>6927</td>\n",
       "      <td>WECC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3142 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS    State  Population Interconnection\n",
       "0      1001  Alabama       55869             EIC\n",
       "1      1003  Alabama      223234             EIC\n",
       "2      1005  Alabama       24686             EIC\n",
       "3      1007  Alabama       22394             EIC\n",
       "4      1009  Alabama       57826             EIC\n",
       "...     ...      ...         ...             ...\n",
       "3137  56037  Wyoming       42343            WECC\n",
       "3138  56039  Wyoming       23464            WECC\n",
       "3139  56041  Wyoming       20226            WECC\n",
       "3140  56043  Wyoming        7805            WECC\n",
       "3141  56045  Wyoming        6927            WECC\n",
       "\n",
       "[3142 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the county-level population data:\n",
    "pop_df = pd.read_csv(metadata_input_dir + 'county_populations_2000_to_2019_long_format.csv')\n",
    "\n",
    "# Subset the dataframe to only the year 2019:\n",
    "pop_df = pop_df[pop_df['Year'] == 2019].copy()\n",
    "\n",
    "# Rename the FIPS variable for consistency with the meteorology data:\n",
    "pop_df.rename(columns={'County_FIPS': 'FIPS'}, inplace=True)\n",
    "\n",
    "# Read in the county-to-state mapping file:\n",
    "state_df = pd.read_csv(metadata_input_dir + 'state_and_county_fips_codes.csv')\n",
    "\n",
    "# Rename the FIPS variable for consistency with the meteorology data and shorten the state name variable:\n",
    "state_df.rename(columns={'county_FIPS': 'FIPS', 'state_name': 'State'}, inplace=True)\n",
    "\n",
    "# Merge the two dataframes together based on common FIPS values:\n",
    "pop_df = pop_df.merge(state_df, on=['FIPS'])\n",
    "\n",
    "# Subset the dataframe and sort by FIPS code:\n",
    "pop_df = pop_df[['FIPS', 'State', 'Population']]\n",
    "pop_df = pop_df.sort_values(['FIPS'])\n",
    "\n",
    "# Create an empty column:\n",
    "pop_df['Interconnection'] = np.nan\n",
    "        \n",
    "# Assign the interconnection:\n",
    "pop_df['Interconnection'].loc[pop_df['State'].isin(wecc)] = 'WECC'\n",
    "pop_df['Interconnection'].loc[pop_df['State'].isin(ercot)] = 'ERCOT'\n",
    "pop_df['Interconnection'].loc[~pop_df['State'].isin(eic)] = 'EIC'\n",
    "\n",
    "# Return the dataframe:\n",
    "pop_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b04f656-5fab-4fcb-86db-63c64db9c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process the interconnection-level time series for a given year\n",
    "def process_ics_meteorology_time_series(data_input_dir: str, data_output_dir: str, year: int):\n",
    "    \n",
    "    # Create a list of all county meteorology files in the input directory:\n",
    "    list_of_files = glob(os.path.join(data_input_dir, str(year), '*.csv'))\n",
    "    \n",
    "    # Loop over that list process each file:\n",
    "    for file in range(len(list_of_files)):\n",
    "    \n",
    "        # Extract the filename from the list:\n",
    "        filename = list_of_files[file].rsplit('/', 1)[1]\n",
    "       \n",
    "        # Extract the time string from the name of the file:\n",
    "        filetime = filename.replace(\"_UTC_County_Mean_Meteorology.csv\", \"\")\n",
    "                \n",
    "        # Read in the .csv file:\n",
    "        met_df = pd.read_csv(list_of_files[file])\n",
    "        \n",
    "        # Compute the 10-m wind speed based on the U10 and V10 variables:\n",
    "        met_df['WSPD'] = (np.sqrt(np.square(met_df['U10']) + np.square(met_df['V10']))).round(2)\n",
    "        \n",
    "        # Merge the population data into the meteorology dataframe based on common FIPS values:\n",
    "        met_df = met_df.merge(pop_df, on=['FIPS'])\n",
    "               \n",
    "        # Compute the fraction of the total population in each state that lives in a given county:\n",
    "        met_df['Population_Sum'] = met_df.groupby('Interconnection')['Population'].transform('sum')\n",
    "        met_df['Population_Fraction'] = met_df['Population'] / met_df['Population_Sum']\n",
    "\n",
    "        # Population-weight the meteorological variables:\n",
    "        met_df['T2_Weighted'] = (met_df['T2'].mul(met_df['Population_Fraction']))\n",
    "        met_df['Q2_Weighted'] = (met_df['Q2'].mul(met_df['Population_Fraction']))\n",
    "        met_df['SWDOWN_Weighted'] = (met_df['SWDOWN'].mul(met_df['Population_Fraction']))\n",
    "        met_df['GLW_Weighted'] = (met_df['GLW'].mul(met_df['Population_Fraction']))\n",
    "        met_df['WSPD_Weighted'] = (met_df['WSPD'].mul(met_df['Population_Fraction']))\n",
    "        \n",
    "        # Sum up the population-weighted meteorological variables by state:\n",
    "        met_df['T2_Sum'] = (met_df.groupby('Interconnection')['T2_Weighted'].transform('sum')).round(2)\n",
    "        met_df['Q2_Sum'] = (met_df.groupby('Interconnection')['Q2_Weighted'].transform('sum')).round(5)\n",
    "        met_df['SWDOWN_Sum'] = (met_df.groupby('Interconnection')['SWDOWN_Weighted'].transform('sum')).round(2)\n",
    "        met_df['GLW_Sum'] = (met_df.groupby('Interconnection')['GLW_Weighted'].transform('sum')).round(2)\n",
    "        met_df['WSPD_Sum'] = (met_df.groupby('Interconnection')['WSPD_Weighted'].transform('sum')).round(2)\n",
    "        \n",
    "        # Copy the output to a new dataframe and remove the non-unique rows:\n",
    "        temp_df = met_df[['Interconnection', 'T2_Sum', 'Q2_Sum', 'SWDOWN_Sum', 'GLW_Sum', 'WSPD_Sum']].copy().drop_duplicates() \n",
    "        \n",
    "        # Add in the time variable:\n",
    "        temp_df['Time_UTC'] = pd.to_datetime(filetime, exact=False, format='%Y_%m_%d_%H')\n",
    "        \n",
    "        # Rename the variables for consistency and reorder them:\n",
    "        temp_df.rename(columns={'T2_Sum': 'T2', 'Q2_Sum': 'Q2', 'SWDOWN_Sum': 'SWDOWN', 'GLW_Sum': 'GLW', 'WSPD_Sum': 'WSPD'}, inplace=True)\n",
    "        temp_df = temp_df[['Time_UTC', 'Interconnection', 'T2', 'Q2', 'SWDOWN', 'GLW', 'WSPD']].copy()\n",
    "        \n",
    "        # Aggregate the output into a new dataframe:\n",
    "        if file == 0:\n",
    "           output_df = temp_df\n",
    "        else:\n",
    "           output_df = pd.concat([output_df, temp_df])\n",
    "            \n",
    "        # Clean up the old dataframes and move to the next file in the loop:\n",
    "        del filename, filetime, met_df, temp_df\n",
    "        \n",
    "    # Sort by state and then time:\n",
    "    output_df = output_df.sort_values(['Interconnection', 'Time_UTC'])\n",
    "\n",
    "    # Create the ouput filename:    \n",
    "    csv_output_filename = os.path.join(data_output_dir, ('Interconnection_Meteorology_' + str(year) + '.csv'))\n",
    "        \n",
    "    # Write out the dataframe to a .csv file:\n",
    "    output_df.to_csv(csv_output_filename, sep=',', index=False)\n",
    "    \n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b38e6c6d-8983-4b44-8901-68b335b9c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year_to_process in range(1992,2017,1):\n",
    "    output_df = process_ics_meteorology_time_series(data_input_dir = data_input_dir, \n",
    "                                                    data_output_dir = data_output_dir, \n",
    "                                                    year = year_to_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d151af-eaf7-434a-914a-1e491aedd82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9.15_std",
   "language": "python",
   "name": "py3.9.15_std"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
